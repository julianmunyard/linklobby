# Phase 4.2: Linktree Import - Research

**Researched:** 2026-01-25
**Domain:** Web scraping, data import, progressive UX
**Confidence:** MEDIUM

## Summary

Linktree does not offer a public API, but their pages are built with Next.js and expose a `__NEXT_DATA__` JSON blob in the HTML that contains all profile data including links, thumbnails, and metadata. This makes scraping straightforward and reliable.

The recommended approach is to fetch the Linktree page HTML server-side, extract the `__NEXT_DATA__` script tag, parse the JSON, and map the link data to our card format. For thumbnails, download images from Linktree's CDN and re-upload to our Supabase storage to ensure permanence and avoid hotlinking.

The primary technical risk is anti-bot protection and rate limiting. Linktree does implement basic protections, but these are manageable with proper HTTP headers and reasonable rate limiting. For initial launch, simple fetching with axios/got should work; if blocking becomes an issue, `got-scraping` provides anti-detection features.

**Primary recommendation:** Use axios to fetch Linktree pages, extract `__NEXT_DATA__` JSON blob, map links to cards with randomized layout pattern, download/re-upload thumbnails to Supabase storage, implement comprehensive error handling with clear user feedback for partial failures.

## Standard Stack

The established libraries/tools for this domain:

### Core
| Library | Version | Purpose | Why Standard |
|---------|---------|---------|--------------|
| axios | ^1.7.x | HTTP requests | Most popular Node.js HTTP client (210M+ monthly downloads), automatic JSON parsing, better error handling than fetch |
| cheerio | ^1.0.x | HTML parsing | Fast jQuery-like syntax for extracting script tags, ~0.5s parse time, 44M+ monthly downloads |
| zod | ^4.3.6 | Data validation | Already in project, perfect for validating scraped data structure, type-safe parsing |

### Supporting
| Library | Version | Purpose | When to Use |
|---------|---------|---------|-------------|
| got-scraping | ^4.x | Anti-bot HTTP client | If axios gets blocked - includes realistic headers, fingerprinting evasion |
| sharp | ^0.33.x | Image processing | If need to resize/optimize imported images before upload |

### Alternatives Considered
| Instead of | Could Use | Tradeoff |
|------------|-----------|----------|
| axios | got | Got has built-in HTTP/2 support but axios has simpler API and larger ecosystem |
| cheerio | JSDOM | JSDOM is full DOM but much slower (~3-4x); cheerio sufficient for script tag extraction |
| Server-side scraping | Client-side scraping | Client approach would expose implementation and IP to rate limiting; server-side is safer |

**Installation:**
```bash
npm install axios cheerio
# Optional if anti-bot protection needed:
npm install got-scraping
# Optional for image optimization:
npm install sharp
```

## Architecture Patterns

### Recommended Project Structure
```
src/
├── app/
│   └── api/
│       └── import/
│           └── linktree/
│               └── route.ts        # API route handler
├── lib/
│   └── import/
│       ├── linktree-scraper.ts     # Core scraping logic
│       ├── linktree-mapper.ts      # Map Linktree data to our Card format
│       ├── layout-generator.ts     # Randomized layout pattern algorithm
│       └── image-downloader.ts     # Download + re-upload images
└── types/
    └── linktree.ts                 # Linktree data structures (Zod schemas)
```

### Pattern 1: Server-Side API Route with Scraping Service
**What:** Create API route that calls scraping service, returns structured data
**When to use:** Always - keeps scraping logic on server, protects implementation details
**Example:**
```typescript
// src/app/api/import/linktree/route.ts
// Source: Next.js App Router best practices
import { scrapeLinktreeProfile } from '@/lib/import/linktree-scraper'
import { mapLinktreeToCards } from '@/lib/import/linktree-mapper'

export async function POST(request: Request) {
  const { username } = await request.json()

  try {
    // Scrape Linktree page
    const profileData = await scrapeLinktreeProfile(username)

    // Map to our card format with randomized layout
    const cards = await mapLinktreeToCards(profileData)

    return Response.json({ success: true, cards })
  } catch (error) {
    return Response.json({
      success: false,
      error: error.message
    }, { status: 400 })
  }
}
```

### Pattern 2: __NEXT_DATA__ Extraction
**What:** Parse Next.js data blob from script tag instead of DOM scraping
**When to use:** Always with Linktree - this is where their data lives
**Example:**
```typescript
// src/lib/import/linktree-scraper.ts
// Source: Linktree scraping community patterns
import axios from 'axios'
import * as cheerio from 'cheerio'

export async function scrapeLinktreeProfile(username: string) {
  const url = `https://linktr.ee/${username}`

  const response = await axios.get(url, {
    headers: {
      'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)',
      'Accept': 'text/html,application/xhtml+xml',
      'Accept-Language': 'en-US,en;q=0.9',
    },
    timeout: 10000, // 10 second timeout
  })

  const $ = cheerio.load(response.data)
  const nextData = $('#__NEXT_DATA__').html()

  if (!nextData) {
    throw new Error('Profile not found or is private')
  }

  const data = JSON.parse(nextData)
  return data.props.pageProps
}
```

### Pattern 3: Download + Re-upload Images (Don't Hotlink)
**What:** Download thumbnails from Linktree, upload to our storage
**When to use:** Always - prevents broken images if Linktree changes/removes them
**Example:**
```typescript
// src/lib/import/image-downloader.ts
// Source: Best practices for web scraping images
import axios from 'axios'
import { uploadCardImage } from '@/lib/supabase/storage'

export async function downloadAndUploadImage(
  imageUrl: string,
  cardId: string
): Promise<string | null> {
  try {
    // Download image as blob
    const response = await axios.get(imageUrl, {
      responseType: 'arraybuffer',
      timeout: 5000,
    })

    // Convert to File object
    const contentType = response.headers['content-type'] || 'image/jpeg'
    const blob = new Blob([response.data], { type: contentType })
    const file = new File([blob], 'thumbnail.jpg', { type: contentType })

    // Upload to our storage
    const result = await uploadCardImage(file, cardId)
    return result.url
  } catch (error) {
    console.warn('Failed to download image:', imageUrl, error)
    return null // Graceful fallback - card created without image
  }
}
```

### Pattern 4: Randomized Layout Pattern Algorithm
**What:** Generate visual rhythm with pattern-based card type/size assignment
**When to use:** During import mapping to create "this is different" feeling
**Example:**
```typescript
// src/lib/import/layout-generator.ts
// Source: Research into visual rhythm patterns
type LayoutPattern = Array<{ type: CardType; size: CardSize; position?: HorizontalPosition }>

// Define rhythm patterns - repeat these for visual consistency
const LAYOUT_PATTERNS: LayoutPattern[] = [
  // Pattern A: Hero + 2 small squares
  [
    { type: 'hero', size: 'big', position: 'left' },
    { type: 'square', size: 'small', position: 'left' },
    { type: 'square', size: 'small', position: 'right' },
  ],
  // Pattern B: 3 small squares + big square
  [
    { type: 'square', size: 'small', position: 'left' },
    { type: 'square', size: 'small', position: 'center' },
    { type: 'square', size: 'small', position: 'right' },
    { type: 'square', size: 'big', position: 'left' },
  ],
  // Pattern C: Big hero + big square
  [
    { type: 'hero', size: 'big', position: 'left' },
    { type: 'square', size: 'big', position: 'left' },
  ],
]

export function generateLayoutPattern(linkCount: number): LayoutPattern {
  const pattern: LayoutPattern = []
  let currentIndex = 0
  let patternIndex = 0

  while (currentIndex < linkCount) {
    const currentPattern = LAYOUT_PATTERNS[patternIndex % LAYOUT_PATTERNS.length]
    pattern.push(...currentPattern.slice(0, linkCount - currentIndex))
    currentIndex += currentPattern.length
    patternIndex++
  }

  return pattern.slice(0, linkCount)
}
```

### Pattern 5: Progressive Feedback with Partial Success
**What:** Import what succeeds, report what fails, don't block on partial failures
**When to use:** Always - some thumbnails may fail, some links may be malformed
**Example:**
```typescript
// src/lib/import/linktree-mapper.ts
// Source: UX best practices for batch operations
export async function mapLinktreeToCards(profileData: any) {
  const links = profileData.links || []
  const layout = generateLayoutPattern(links.length)

  const results = await Promise.allSettled(
    links.map(async (link, index) => {
      const layoutItem = layout[index]

      // Download thumbnail if available
      let imageUrl = null
      if (link.thumbnailUrl) {
        imageUrl = await downloadAndUploadImage(link.thumbnailUrl, link.id)
      }

      return {
        card_type: layoutItem.type,
        title: link.title,
        url: link.url,
        size: layoutItem.size,
        position: layoutItem.position || 'left',
        content: { imageUrl },
      }
    })
  )

  // Separate successes from failures
  const successful = results
    .filter(r => r.status === 'fulfilled')
    .map(r => r.value)

  const failed = results
    .filter(r => r.status === 'rejected')
    .map((r, i) => ({ index: i, reason: r.reason }))

  return { cards: successful, failures: failed }
}
```

### Anti-Patterns to Avoid
- **Blocking entire import on single failure:** Use `Promise.allSettled` not `Promise.all` - import what succeeds
- **Hotlinking Linktree images:** Always download and re-upload to own storage
- **Client-side scraping:** Exposes IP to rate limiting, harder to add anti-bot measures later
- **Rigid card type mapping:** Don't force "Spotify link = big hero" - use layout pattern for variety
- **No timeout:** Set reasonable timeouts (10s for page fetch, 5s per image) to prevent hanging

## Don't Hand-Roll

Problems that look simple but have existing solutions:

| Problem | Don't Build | Use Instead | Why |
|---------|-------------|-------------|-----|
| HTTP requests with retry logic | Custom fetch wrapper | axios with axios-retry or got with built-in retry | Built-in timeout, redirect handling, decompression, proper error types |
| HTML parsing | Regex on HTML strings | cheerio | HTML is not regular - cheerio handles malformed HTML, entities, nested structures |
| Anti-bot detection | Custom headers object | got-scraping | TLS fingerprinting, realistic browser headers, cookie handling, redirect chain tracking |
| Image format detection | File extension checking | Content-Type header + validation | Extensions lie - use actual content type from response headers |
| Rate limiting | setTimeout delays | p-queue or bottleneck | Proper concurrent request limiting, priority queues, backoff strategies |

**Key insight:** Web scraping edge cases are extensive - use battle-tested libraries that handle encoding issues, malformed HTML, redirect chains, compression, timeouts, and error recovery.

## Common Pitfalls

### Pitfall 1: Assuming __NEXT_DATA__ Structure is Stable
**What goes wrong:** Linktree updates their data structure, import breaks silently
**Why it happens:** Next.js page props can change with any deploy
**How to avoid:**
- Use Zod schemas to validate structure before processing
- Gracefully handle missing/extra fields
- Log structure changes for monitoring
**Warning signs:**
```typescript
// BAD - assumes structure
const links = data.props.pageProps.links

// GOOD - validate with Zod
const LinktreeSchema = z.object({
  props: z.object({
    pageProps: z.object({
      links: z.array(LinkSchema),
    }),
  }),
})

const validated = LinktreeSchema.safeParse(data)
if (!validated.success) {
  throw new Error('Linktree data structure changed')
}
```

### Pitfall 2: Not Handling Private/Invalid Profiles
**What goes wrong:** User enters username that doesn't exist or is private, import hangs or crashes
**Why it happens:** Linktree returns different HTML for private/missing profiles
**How to avoid:**
- Check for `__NEXT_DATA__` presence before parsing
- Return clear error messages based on response structure
- Don't assume 200 status = valid profile
**Warning signs:** Timeout errors, JSON parse failures, undefined errors

### Pitfall 3: Image Download Blocking Card Creation
**What goes wrong:** Thumbnail download fails (404, timeout), entire card import fails
**Why it happens:** Using `await` without error handling, treating images as required
**How to avoid:**
- Wrap image downloads in try/catch, return null on failure
- Create card without image if download fails
- Use `Promise.allSettled` for batch operations
**Warning signs:** Partial imports failing completely, timeout errors

### Pitfall 4: Rate Limiting on Rapid Imports
**What goes wrong:** User imports, then immediately tries another username, gets blocked
**Why it happens:** Linktree likely has per-IP rate limits (threshold unknown)
**How to avoid:**
- Add client-side cooldown (disable import button for 5-10 seconds)
- Server-side: track requests per IP, enforce minimum delay
- If needed, implement queue system for multiple imports
**Warning signs:** 429 status codes, connection resets, CAPTCHA challenges

### Pitfall 5: Not Validating URLs Before Card Creation
**What goes wrong:** Malformed URLs from Linktree break card rendering or database constraints
**Why it happens:** Assuming Linktree only has valid URLs
**How to avoid:**
- Validate URLs with Zod's `.url()` or URL constructor
- Skip malformed URLs with warning in failures array
- Don't trust external data - validate everything
**Warning signs:** Database errors on insert, broken links in UI

## Code Examples

Verified patterns from official sources:

### Complete Linktree Data Schema
```typescript
// src/types/linktree.ts
// Source: linktree-scraper example_data.json + Zod validation best practices
import { z } from 'zod'

const LinktreeLinkSchema = z.object({
  id: z.number(),
  title: z.string(),
  url: z.string().url(),
  type: z.enum(['HEADER', 'CLASSIC', 'MUSIC', 'VIDEO']),
  position: z.number(),
  thumbnailUrl: z.string().url().optional().nullable(),
  locked: z.boolean().optional(),
  isForwarding: z.boolean().optional(),
})

const LinktreeAccountSchema = z.object({
  username: z.string(),
  pageTitle: z.string().optional().nullable(),
  description: z.string().optional().nullable(),
  tier: z.string(),
  isActive: z.boolean(),
})

export const LinktreeDataSchema = z.object({
  props: z.object({
    pageProps: z.object({
      account: LinktreeAccountSchema,
      links: z.array(LinktreeLinkSchema),
      socialLinks: z.array(z.any()).optional(), // Twitter, Instagram, etc.
    }),
  }),
})

export type LinktreeData = z.infer<typeof LinktreeDataSchema>
export type LinktreeLink = z.infer<typeof LinktreeLinkSchema>
```

### Username/URL Auto-Detection
```typescript
// src/lib/import/linktree-scraper.ts
// Source: Best practices for flexible input handling
export function normalizeLinktreeInput(input: string): string {
  // Remove whitespace
  const cleaned = input.trim()

  // If it's a URL, extract username
  if (cleaned.includes('linktr.ee/') || cleaned.includes('linktree.com/')) {
    const match = cleaned.match(/linktr\.ee\/([^/?#]+)/)
    if (match) return match[1]
  }

  // Otherwise treat as username
  return cleaned.replace(/^@/, '') // Remove @ if present
}
```

### Progressive UI Feedback Pattern
```typescript
// Client component pattern
// Source: Next.js Server Actions + useActionState best practices
'use client'

import { useActionState } from 'react'
import { importLinktreeAction } from '@/app/actions/import-linktree'

export function LinktreeImportForm() {
  const [state, formAction, pending] = useActionState(importLinktreeAction, null)

  return (
    <form action={formAction}>
      <input
        name="username"
        placeholder="Enter Linktree username or URL"
        disabled={pending}
      />
      <button disabled={pending}>
        {pending ? 'Importing...' : 'Import from Linktree'}
      </button>

      {state?.error && (
        <p className="text-red-500">{state.error}</p>
      )}

      {state?.success && (
        <p className="text-green-500">
          Imported {state.imported} links
          {state.failed > 0 && ` (${state.failed} failed)`}
        </p>
      )}
    </form>
  )
}
```

## State of the Art

| Old Approach | Current Approach | When Changed | Impact |
|--------------|------------------|--------------|--------|
| Unofficial Linktree API endpoints | __NEXT_DATA__ scraping | ~2020 (Linktree rebuilt on Next.js) | More reliable - data embedded in every page load |
| Client-side scraping with CORS proxies | Server-side scraping in API routes | Next.js 13+ App Router | Better security, no CORS issues, hides implementation |
| Promise.all for batch operations | Promise.allSettled | ES2020 | Partial success handling - don't fail everything on single error |
| Manual header management | got-scraping library | 2021+ | Automated anti-bot evasion if needed |
| Skeleton loaders only | Skeleton + percentage indicators | 2024+ UX best practices | Better perceived performance for >3s operations |

**Deprecated/outdated:**
- Linktree unofficial API: No longer reliable, structure changed
- Request library: Deprecated in 2020, use axios or got
- Puppeteer for simple scraping: Overkill when __NEXT_DATA__ is available - use only if JS rendering needed

## Open Questions

Things that couldn't be fully resolved:

1. **Exact rate limit thresholds**
   - What we know: Linktree implements rate limiting, community recommends proxies for scale
   - What's unclear: Specific request/minute limits, whether limits are per-IP or per-username
   - Recommendation: Start with reasonable delays (5-10s between imports), monitor for 429 responses, add queue if needed

2. **Linktree link type to card type mapping**
   - What we know: Linktree has types like 'HEADER', 'CLASSIC', 'MUSIC', 'VIDEO'
   - What's unclear: Whether we should respect these types or purely use layout pattern
   - Recommendation: Context says "layout pattern decides card type" - ignore Linktree types, use randomized pattern

3. **Handling empty canvas vs. existing cards**
   - What we know: Context says ask user "add to existing or start fresh"
   - What's unclear: UI pattern for this choice (dialog, inline prompt, etc.)
   - Recommendation: Show alert dialog before import if cards exist, let user choose

4. **Import progress for large profiles**
   - What we know: Best practice is skeleton screens for 1-3s, progress bars for 3s+
   - What's unclear: Expected import time for typical Linktree (10-30 links)
   - Recommendation: Use optimistic UI - show skeleton cards immediately, hydrate as data arrives

## Sources

### Primary (HIGH confidence)
- [Linktree scraper example data structure](https://github.com/benkaiser/linktree-scraper/blob/master/example_data.json) - Actual __NEXT_DATA__ format
- [ScrapeCreators Linktree guide](https://scrapecreators.com/blog/how-to-scrape-linktree) - __NEXT_DATA__ extraction approach
- [Next.js Server Actions documentation](https://nextjs.org/docs/13/app/building-your-application/data-fetching/server-actions-and-mutations) - Official patterns
- Current project's storage.ts - Existing upload pattern to follow

### Secondary (MEDIUM confidence)
- [Axios vs Got vs Fetch comparison (ZenRows)](https://www.zenrows.com/blog/axios-vs-got-vs-fetch) - HTTP client selection criteria
- [Node.js web scraping best practices (ThunderBit)](https://thunderbit.com/blog/nodejs-web-scraping-best-practices) - Anti-detection, error handling
- [UX loading patterns (Pencil & Paper)](https://www.pencilandpaper.io/articles/ux-pattern-analysis-loading-feedback) - Progressive feedback
- [Toast notification best practices (LogRocket)](https://blog.logrocket.com/ux-design/toast-notifications/) - Partial failure messaging
- [React Plock masonry layout](https://github.com/askides/react-plock) - Pattern-based layout inspiration

### Tertiary (LOW confidence)
- WebSearch results on Linktree anti-bot protection - Anecdotal, no specific thresholds
- Layout algorithm searches - No direct Linktree import patterns found, applied general principles

## Metadata

**Confidence breakdown:**
- __NEXT_DATA__ approach: HIGH - Verified in example data, multiple sources confirm
- HTTP client choice (axios): HIGH - Project already uses it implicitly via Next.js patterns
- Rate limiting specifics: LOW - No official documentation, community anecdotes only
- Layout algorithm: MEDIUM - Pattern-based approach is sound but no verified Linktree-specific examples
- Error handling patterns: HIGH - Next.js Server Actions + useActionState is official pattern

**Research date:** 2026-01-25
**Valid until:** ~60 days (stable domain - Linktree structure changes infrequently, axios/cheerio mature)

**Notes:**
- Linktree has a developer program but it's not publicly accessible - scraping is the only option
- No official API means scraping could break if Linktree changes structure - Zod validation critical
- Project already has image upload infrastructure (storage.ts) - reuse this pattern
- Project uses Next.js App Router, Server Actions, Zod, Supabase - all patterns align
